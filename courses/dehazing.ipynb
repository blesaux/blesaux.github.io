{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOGS - ARDF Projects - Dehazing\n",
    "\n",
    "This file is a helper for loading the dehazing data\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the dataset\n",
    "\n",
    "The dataset is a Pytorch class. The datasets objects, used along a dataloader provide de data in a pytorch format.\n",
    "The following class, takes numpy arrays for the input data and the targets. It is also possible to operate a crop on the data.\n",
    "\n",
    "*Note:* This class does not operate a data normalization, normalization must be either done before creating the dataset or modify the definition of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Main Class for Image Folder loader.\"\"\"\n",
    "\n",
    "    def __init__(self, data, targets, crop=False, imsize=256):\n",
    "        \"\"\"Init function.\"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.crop = crop\n",
    "        self.imsize = imsize\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get item.\"\"\"\n",
    "\n",
    "        data, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.crop:\n",
    "            w, h, _ = data.shape\n",
    "            x1 = random.randint(0, w - self.imsize)\n",
    "            y1 = random.randint(0, h - self.imsize)\n",
    "            data = data[x1:x1+self.imsize, y1:y1+self.imsize]\n",
    "            target = target[x1:x1+self.imsize, y1:y1+self.imsize]\n",
    "        \n",
    "        # in troch channels are first\n",
    "        data = data.transpose(2,0,1)\n",
    "        target = target.transpose(2,0,1)\n",
    "\n",
    "        # convert to float32\n",
    "        data = data.astype(np.float32)\n",
    "        target = target.astype(np.float32)\n",
    "\n",
    "        # convert to torch tensors\n",
    "        data = torch.from_numpy(data)\n",
    "        target = torch.from_numpy(target)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length.\"\"\"\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "We provide the data in the form of numpy arrays, you can download them here:\n",
    "* Train data [here](https://drive.google.com/open?id=19bzWcf5g3zFR5njtLhvup31No5buOUP_)\n",
    "* Train GT [here](https://drive.google.com/open?id=14e2i1JIH6af0nGAHDS2jUyN5VZwJ_Bnv)\n",
    "\n",
    "Or from here (Mirror):\n",
    "* Train data [here](https://drive.google.com/file/d/1yHCCPyBXEHd0YUmnmF6AnLBb9qVp0yOr/view?usp=sharing)\n",
    "* Train GT [here](https://drive.google.com/file/d/1Id6c3K8-O3GfSO0L60NrpGxKhejUIcJi/view?usp=sharing)\n",
    "* Validation data [here](https://drive.google.com/file/d/172GD31CUwsBOpjZQFTbPqztxm9OFy22N/view?usp=sharing)\n",
    "\n",
    "Supposing they are stored on you Google Drive in the ```data/dehazing``` folder, you can mount the folder using the following code. Set ```USE_COLAB``` to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_COLAB = False\n",
    "if USE_COLAB:\n",
    "    # mount the goole drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # download cifar on GoogleDrive\n",
    "    data_dir = \"/content/drive/My Drive/data/dehazing\"\n",
    "else:\n",
    "    data_dir = \"data/dehazing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_th = np.load(os.path.join(data_dir, \"train_data.npy\"))\n",
    "gt_th = np.load(os.path.join(data_dir, \"train_gt.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data loader and iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(data_th, gt_th, crop=True, imsize=256)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for inputs, targets in dataloader:\n",
    "    print(inputs.size(), targets.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_th = np.load(os.path.join(data_dir, \"val_data.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
